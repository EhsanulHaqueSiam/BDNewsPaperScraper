name: CI/CD Pipeline

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  schedule:
    # Run scraping daily at 6 AM UTC
    - cron: '0 6 * * *'

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
      
      - name: Run linting
        run: |
          flake8 BDNewsPaper/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 BDNewsPaper/ --count --exit-zero --max-complexity=10 --max-line-length=100 --statistics
      
      - name: Run tests
        run: |
          pytest tests/ -v --tb=short --cov=BDNewsPaper --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        if: matrix.python-version == '3.11'
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  scrape:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    needs: test
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
      
      - name: Run scrapers
        run: |
          scrapy crawl prothomalo -a max_pages=5 -a categories=Bangladesh || true
          scrapy crawl thedailystar -a max_pages=5 -a categories=bangladesh || true
          scrapy crawl dhakatribune -a max_pages=5 -a categories=bangladesh || true
        env:
          LOG_LEVEL: INFO
      
      - name: Upload database
        uses: actions/upload-artifact@v4
        with:
          name: news-database
          path: news_articles.db
          retention-days: 30

  docker:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        run: |
          docker build -t bdnews-scraper:latest .
      
      - name: Test Docker image
        run: |
          docker run --rm bdnews-scraper:latest python -c "import BDNewsPaper.api; print('OK')"
